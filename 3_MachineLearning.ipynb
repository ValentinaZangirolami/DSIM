{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yp1VzNt8tfYu"
   },
   "source": [
    "**PART 3 - DSIM PROJECT**\n",
    "\n",
    "Francesca De Cola, Valentina Moretto, Valentina Zangirolami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fab5RpKtfYx"
   },
   "source": [
    "In this notebook, we have used VGGFace neural network. This is provided by the following link of github (https://github.com/rcmalli/keras-vggface.git). We decided to use this network because is trained with facial images while a classical pre-trained network provided by keras is trained on ImageNet dataset that is more different than our case. \n",
    "\n",
    "Pre-trained network are more useful to improve performance.\n",
    "\n",
    "In this notebook, VGGFace is used for the extraction of the features of our images:\n",
    "this technique permits to reduce dimensionality of the data and extract the important features of images.\n",
    "\n",
    "Finally, we compare different machine learning alghoritms with hyperparameters optimazation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G39ZKDkEtfYy",
    "outputId": "d3e2a07f-8df4-4e22-e2dd-30783cb7b122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to c:\\users\\valen\\appdata\\local\\temp\\pip-req-build-6iej238_\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\valen\\anaconda3\\lib\\site-packages (from keras-vggface==0.6) (1.20.3)\n",
      "Collecting scipy>=0.14\n",
      "  Using cached scipy-1.6.3-cp37-cp37m-win_amd64.whl (32.6 MB)\n",
      "Requirement already satisfied: h5py in c:\\users\\valen\\appdata\\roaming\\python\\python37\\site-packages (from keras-vggface==0.6) (2.10.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\valen\\anaconda3\\lib\\site-packages (from keras-vggface==0.6) (5.2.0)\n",
      "Requirement already satisfied: keras in c:\\users\\valen\\appdata\\roaming\\python\\python37\\site-packages (from keras-vggface==0.6) (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\valen\\anaconda3\\lib\\site-packages (from keras-vggface==0.6) (1.11.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\valen\\anaconda3\\lib\\site-packages (from keras-vggface==0.6) (3.13)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\valen\\appdata\\roaming\\python\\python37\\site-packages (from keras->keras-vggface==0.6) (1.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\valen\\appdata\\roaming\\python\\python37\\site-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.6.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git 'C:\\Users\\valen\\AppData\\Local\\Temp\\pip-req-build-6iej238_'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in c:\\users\\valen\\appdata\\roaming\\python\\python37\\site-packages (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\valen\\anaconda3\\lib\\site-packages (from keras_applications) (1.20.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\valen\\appdata\\roaming\\python\\python37\\site-packages (from keras_applications) (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\valen\\anaconda3\\lib\\site-packages (from h5py->keras_applications) (1.11.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\valen\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\valen\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\valen\\anaconda3\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\valen\\anaconda3\\lib\\site-packages (from scikit-learn) (1.20.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\valen\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn) (1.6.3)\n"
     ]
    }
   ],
   "source": [
    "#!pip install git+https://github.com/rcmalli/keras-vggface.git --user\n",
    "#!pip install keras_applications\n",
    "#!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJkj1-Q8tfY0"
   },
   "source": [
    "**Load and import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ib86Vg3tfY0",
    "outputId": "06ce0b74-e482-4041-e1e4-27c8d89d55c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras_vggface \n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.utils import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Er30dl8UjQ6S"
   },
   "outputs": [],
   "source": [
    "import keras_applications\n",
    "import keras\n",
    "from keras_vggface import utils\n",
    "\n",
    "from PIL import Image\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split , StratifiedKFold, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2WMfisUtfY2"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist \n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.utils import to_categorical, np_utils \n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras_vggface import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOnr2e-DtfY2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foSh5ycMtfY3"
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKJjjeQGtfY3"
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnZbuG5htfY4"
   },
   "source": [
    "**Seed for reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDNWvCEJtfY4"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xENqlH9togll"
   },
   "source": [
    "**Preprocessing e Feature extractor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QGJwmXutfY5"
   },
   "source": [
    "We load a dataset of images created in the previous notebook (creation_dataset.ipynb). It contains facial images related to the seven emotions (angry, happy, sad, neutral, surprise, fear, disgust)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ztCbbhQj09g",
    "outputId": "f30103ac-ed7d-41f9-9af5-5ecd2da6cadd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2269, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=np.load(\"C:/Users/valen/Desktop/magistrale/DSIM/dataset_imgs.npz\")\n",
    "label=train['Y'] #label\n",
    "img=train['X'] #images\n",
    "img.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC8K5ky5tfY6"
   },
   "source": [
    "Initially, we use pre-trained neural network 'VGGFace' such as feature extractor. We load senet50 model of VGGFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnbW8r-Goda5",
    "outputId": "6f0ac69e-56c6-42b1-a3f6-7ffb357d4f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\valen\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\valen\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\valen\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\valen\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\valen\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\valen\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\valen\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\valen\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = VGGFace(include_top = False, input_shape = (224, 224, 3), model='senet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE7RF-iptfY6"
   },
   "source": [
    "Before training phase, we transform pixel of images to float and apply preprocessing function of resnet-50 of vggface. This function rescale pixel of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4sRQ_uIokMP"
   },
   "outputs": [],
   "source": [
    "img=img.astype('float64')\n",
    "img = utils.preprocess_input(img,version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXfpBjJetfY7"
   },
   "source": [
    "Structure of resnet-50 VGGFace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWzIAMN3ovat",
    "outputId": "685fd733-6203-4653-d7d5-f3abdd4acb32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 256)          0           conv2_1_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_down (Conv2D)       (None, 1, 1, 16)     4112        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1, 1, 16)     0           conv2_1_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_up (Conv2D)         (None, 1, 1, 256)    4352        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1, 1, 256)    0           conv2_1_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           multiply_1[0][0]                 \n",
      "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 256)          0           conv2_2_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_down (Conv2D)       (None, 1, 1, 16)     4112        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1, 1, 16)     0           conv2_2_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_up (Conv2D)         (None, 1, 1, 256)    4352        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1, 1, 256)    0           conv2_2_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           multiply_2[0][0]                 \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 256)          0           conv2_3_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_down (Conv2D)       (None, 1, 1, 16)     4112        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1, 1, 16)     0           conv2_3_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_up (Conv2D)         (None, 1, 1, 256)    4352        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 1, 1, 256)    0           conv2_3_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 55, 55, 256)  0           multiply_3[0][0]                 \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 512)          0           conv3_1_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1, 512)    0           global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_down (Conv2D)       (None, 1, 1, 32)     16416       reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 1, 1, 32)     0           conv3_1_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_up (Conv2D)         (None, 1, 1, 512)    16896       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1, 1, 512)    0           conv3_1_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           multiply_4[0][0]                 \n",
      "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 512)          0           conv3_2_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1, 512)    0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_down (Conv2D)       (None, 1, 1, 32)     16416       reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1, 1, 32)     0           conv3_2_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_up (Conv2D)         (None, 1, 1, 512)    16896       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 1, 1, 512)    0           conv3_2_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           multiply_5[0][0]                 \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 512)          0           conv3_3_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1, 512)    0           global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_down (Conv2D)       (None, 1, 1, 32)     16416       reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 1, 1, 32)     0           conv3_3_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_up (Conv2D)         (None, 1, 1, 512)    16896       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 1, 1, 512)    0           conv3_3_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           multiply_6[0][0]                 \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 512)          0           conv3_4_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1, 512)    0           global_average_pooling2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_down (Conv2D)       (None, 1, 1, 32)     16416       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 1, 1, 32)     0           conv3_4_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_up (Conv2D)         (None, 1, 1, 512)    16896       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1, 1, 512)    0           conv3_4_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           multiply_7[0][0]                 \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 1024)         0           conv4_1_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 1, 1024)   0           global_average_pooling2d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 1, 1, 64)     0           conv4_1_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1, 1, 1024)   0           conv4_1_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           multiply_8[0][0]                 \n",
      "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 1024)         0           conv4_2_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1, 1024)   0           global_average_pooling2d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1, 1, 64)     0           conv4_2_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 1, 1, 1024)   0           conv4_2_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           multiply_9[0][0]                 \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_10 (Gl (None, 1024)         0           conv4_3_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 1, 1024)   0           global_average_pooling2d_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 1, 1, 64)     0           conv4_3_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 1, 1, 1024)   0           conv4_3_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           multiply_10[0][0]                \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Gl (None, 1024)         0           conv4_4_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 1, 1024)   0           global_average_pooling2d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 1, 1, 64)     0           conv4_4_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 1, 1, 1024)   0           conv4_4_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           multiply_11[0][0]                \n",
      "                                                                 activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_12 (Gl (None, 1024)         0           conv4_5_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 1, 1024)   0           global_average_pooling2d_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 1, 1, 64)     0           conv4_5_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1, 1, 1024)   0           conv4_5_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           multiply_12[0][0]                \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_13 (Gl (None, 1024)         0           conv4_6_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 1, 1, 1024)   0           global_average_pooling2d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 1, 1, 64)     0           conv4_6_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 1, 1, 1024)   0           conv4_6_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           multiply_13[0][0]                \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_14 (Gl (None, 2048)         0           conv5_1_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 1, 2048)   0           global_average_pooling2d_14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_down (Conv2D)       (None, 1, 1, 128)    262272      reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 1, 1, 128)    0           conv5_1_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_up (Conv2D)         (None, 1, 1, 2048)   264192      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 1, 1, 2048)   0           conv5_1_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           multiply_14[0][0]                \n",
      "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_15 (Gl (None, 2048)         0           conv5_2_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 1, 1, 2048)   0           global_average_pooling2d_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_down (Conv2D)       (None, 1, 1, 128)    262272      reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 1, 1, 128)    0           conv5_2_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_up (Conv2D)         (None, 1, 1, 2048)   264192      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 1, 1, 2048)   0           conv5_2_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           multiply_15[0][0]                \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_16 (Gl (None, 2048)         0           conv5_3_1x1_increase/bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 1, 1, 2048)   0           global_average_pooling2d_16[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_down (Conv2D)       (None, 1, 1, 128)    262272      reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 1, 1, 128)    0           conv5_3_1x1_down[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_up (Conv2D)         (None, 1, 1, 2048)   264192      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 1, 1, 2048)   0           conv5_3_1x1_up[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           multiply_16[0][0]                \n",
      "                                                                 activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_81[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 26,092,144\n",
      "Trainable params: 26,039,024\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQMGuSHutfY8"
   },
   "source": [
    "In the following lines we focus on feature extraction. We cut the base model at the layer *global_average_pooling_2d_14* and with the command *predict* we extract feauture of our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YrGCqUujo2OM"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer(\"global_average_pooling2d_14\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zHJf0h8co4qi",
    "outputId": "c344a555-04ff-4dbf-f6bd-72e4192a3b12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2269, 2048)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = model.predict(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTBLFKI_tfY9"
   },
   "source": [
    "Initially, we divide the complete dataset into two partition (train and test set). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVwI1ombtfY9"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(img, label, test_size = .2, random_state = SEED, stratify = label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5GJGTSGpCQ9"
   },
   "source": [
    "**Cross validation 5-folds**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSANWBcDtfY9"
   },
   "source": [
    "We used a 5-folds cross validation to evaluate three model:\n",
    "1. Random Forest\n",
    "2. Support Vector Machine\n",
    "3. K-nearest neighbord\n",
    "\n",
    "Furthermore, this approch is used for tune and test the three models. \n",
    "\n",
    "For hyperparameters optimization, we use a grid search randomize that allows to select a combination of hyperparameters randomly with efficient computation time than grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOITbcj3pAYF"
   },
   "outputs": [],
   "source": [
    "kfold_acc = {}\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cIWaJ0ypRRJ"
   },
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pH0Nf3qVtfY_"
   },
   "source": [
    "We define a limited range of possible value for each hyperparameters of random forest:\n",
    "* number of trees: a range of value from 200 to 2000 (n_estimators)\n",
    "* max_depth: represents the maximum depth of tree (10,110)\n",
    "* max_features: the number of features to consider for each split\n",
    "* min_samples_split: minimum number of samples required to split a node \n",
    "* min_samples_leaf: minimum number of samples required at each leaf node\n",
    "* bootstrap: boolean value for the choice to use bootstrap samples when building trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgoWC3entfY_",
    "outputId": "ec3e0eb1-527a-4520-cc03-beeb20938dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8947658402203856"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "clf = RandomForestClassifier()\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'log2']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "rf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 100, cv = kfold, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)\n",
    "rf_random.best_params_\n",
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FzJSdGutfZA"
   },
   "source": [
    "We evaluate model to test set with best parameters selecting by randomized grid search. \n",
    "\n",
    "We define classification report and confusion matrix that can be used to evaluate performance for each classes.\n",
    "\n",
    "Metrics:\n",
    "* Precision, represents the number of correctly predicted instances\n",
    "* Recall, is a measure of sensibility of the model. It is a fraction of number of corrected prediction and number of total cases effective\n",
    "* f1-score, is an harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8UWVe5wtfZA",
    "outputId": "45dd7b2c-0db2-4fc9-e655-101f4af96f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.84      0.92      0.88        64\n",
      "     disgust       0.88      0.87      0.87        60\n",
      "        fear       0.92      0.87      0.89        63\n",
      "       happy       0.98      0.92      0.95        64\n",
      "     neutral       0.85      0.93      0.89        69\n",
      "         sad       0.92      0.78      0.84        73\n",
      "    surprise       0.85      0.95      0.90        61\n",
      "\n",
      "    accuracy                           0.89       454\n",
      "   macro avg       0.89      0.89      0.89       454\n",
      "weighted avg       0.89      0.89      0.89       454\n",
      "\n",
      "Confusion matrix:\n",
      "[[59  3  0  0  0  2  0]\n",
      " [ 6 52  0  0  0  1  1]\n",
      " [ 0  0 55  0  2  1  5]\n",
      " [ 0  1  0 59  2  0  2]\n",
      " [ 0  0  2  1 64  1  1]\n",
      " [ 5  3  2  0  5 57  1]\n",
      " [ 0  0  1  0  2  0 58]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a42fed0a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred=rf_random.predict(x_test)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Confusion matrix:')\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysDMW0uXtfZB"
   },
   "source": [
    "The score of accuracy is 89%. Class 'happy' perform very well in terms of precision, recall and f1-score. Other classes have always high value of metrics, but the power of classification is lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxKly2ljwiMt"
   },
   "source": [
    "**SVC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d46HuN7TtfZB"
   },
   "source": [
    "We define a grid of hyperparameters for SVC:\n",
    "* C is a parameters of regularization\n",
    "* class_weight is used to choice to balance or not the label classes\n",
    "* gamma represent the kernel coefficients\n",
    "* kernel represent the kernel type to be used in the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkE6xL2-tfZB",
    "outputId": "c1cc86b0-bcb1-4381-fcf4-aa4d92f3abfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.88276201 0.78537698 0.31512968 0.14676605 0.14676605 0.14676605\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.91361652 0.89158133 0.67342922 0.14676605 0.26574963 0.14852817\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.92639671 0.91846525 0.59277455 0.1529529  0.80168626 0.74570314\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.92551565 0.92243098 0.52666122 0.1520524  0.88672677 0.8721864\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.92551565 0.92243098 0.48038432 0.15072789 0.90832531 0.9065632\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9263967091635792"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "svc_grid = {'C': [0.1, 1, 10, 100, 1000], 'class_weight':['balanced','None'],'gamma': ['scale', 'auto'], 'kernel':  ['poly', 'rbf', 'sigmoid']}\n",
    "svc_random = RandomizedSearchCV(estimator = clf, param_distributions = svc_grid, n_iter = 60, cv = kfold, verbose=2, random_state=42, n_jobs = -1)\n",
    "svc_random.fit(img, label)\n",
    "svc_random.best_params_\n",
    "svc_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lf5YnWEAtfZC"
   },
   "source": [
    "We evaluate model to test set with best parameters selecting by randomized grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imhTWgbzwpSO",
    "outputId": "f2869ea6-d0ab-48f6-c25d-a35bbff5e524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       1.00      1.00      1.00        64\n",
      "     disgust       1.00      1.00      1.00        60\n",
      "        fear       1.00      1.00      1.00        63\n",
      "       happy       1.00      1.00      1.00        64\n",
      "     neutral       1.00      1.00      1.00        69\n",
      "         sad       1.00      1.00      1.00        73\n",
      "    surprise       1.00      1.00      1.00        61\n",
      "\n",
      "    accuracy                           1.00       454\n",
      "   macro avg       1.00      1.00      1.00       454\n",
      "weighted avg       1.00      1.00      1.00       454\n",
      "\n",
      "Confusion matrix:\n",
      "[[64  0  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0  0]\n",
      " [ 0  0 63  0  0  0  0]\n",
      " [ 0  0  0 64  0  0  0]\n",
      " [ 0  0  0  0 69  0  0]\n",
      " [ 0  0  0  0  0 73  0]\n",
      " [ 0  0  0  0  0  0 61]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a431121eb8>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_svc=svc_random.predict(x_test)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, y_pred_svc))\n",
    "\n",
    "print('Confusion matrix:')\n",
    "cm=confusion_matrix(y_test, y_pred_svc)\n",
    "print(cm)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1kMUTQrtfZD"
   },
   "source": [
    "Accuracy value of cross validation is very high (92%). In the test phase, we obtain an accuracy of 100%. SVC results is better than random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vgv-QFsup9DX"
   },
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbifOBxAtfZD"
   },
   "source": [
    "We define a grid of hyperparameters of KNN:\n",
    "* n_neighbors represent the number of neighbors consider in KNN\n",
    "* weights is the weight function used in prediction (Uniform: All points in each neighborhood are weighted equally, Distance weight is the inverse of the points distance)\n",
    "* p represent the parameter of minkowski distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLMFVawPtfZD",
    "outputId": "707420ec-f1a3-4034-e2d7-99c4e19a5d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 95 candidates, totalling 475 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8386965020275987"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_grid = {'n_neighbors': [5,7,9,12, 15, 20, 25, 30, 35, 40, 50], 'weights':['uniform','distance'],'p': list(range(1,6))}\n",
    "knn_random = RandomizedSearchCV(estimator = knn, param_distributions = knn_grid, n_iter = 95, cv = kfold, verbose=2, random_state=42, n_jobs = -1)\n",
    "knn_random.fit(img, label)\n",
    "knn_random.best_params_\n",
    "knn_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FF7GSG1tfZE"
   },
   "source": [
    "We evaluate model to test set with best parameters selecting by randomized grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThcqmkrJp_z4",
    "outputId": "3c421824-f414-4271-839a-700de9a0d1ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       1.00      1.00      1.00        64\n",
      "     disgust       1.00      1.00      1.00        60\n",
      "        fear       1.00      1.00      1.00        63\n",
      "       happy       1.00      1.00      1.00        64\n",
      "     neutral       1.00      1.00      1.00        69\n",
      "         sad       1.00      1.00      1.00        73\n",
      "    surprise       1.00      1.00      1.00        61\n",
      "\n",
      "    accuracy                           1.00       454\n",
      "   macro avg       1.00      1.00      1.00       454\n",
      "weighted avg       1.00      1.00      1.00       454\n",
      "\n",
      "Confusion matrix:\n",
      "[[64  0  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0  0]\n",
      " [ 0  0 63  0  0  0  0]\n",
      " [ 0  0  0 64  0  0  0]\n",
      " [ 0  0  0  0 69  0  0]\n",
      " [ 0  0  0  0  0 73  0]\n",
      " [ 0  0  0  0  0  0 61]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a4310c5160>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_knn=knn_random.predict(x_test)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "print('Confusion matrix:')\n",
    "cm=confusion_matrix(y_test, y_pred_knn)\n",
    "print(cm)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skznkmP2tfZE"
   },
   "source": [
    "In the test set we obtain a very high value of accuracy (100%) but in the cross validation phase we obtain the worst value. For this reason, we save only the svc models to compare it with subsequent algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0Y5TQVltfZF",
    "outputId": "9b41e642-6c56-4487-eeff-d58137356cc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/valen/Desktop/magistrale/DSIM/svc_model.sav']"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'C:/Users/valen/Desktop/magistrale/DSIM/svc_model.sav'\n",
    "joblib.dump(svc_random, filename)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MachineLearning_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
